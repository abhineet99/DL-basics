{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For importing dependencies. Tweepy is a python library which makes using Twitter API an easier task. jsonlines and json are the formats that we are going to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import jsonlines\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard twitter api protocol. Please update the following cells with your own keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key=\"\"\n",
    "consumer_secret=\"\"\n",
    "access_token=\"\"\n",
    "access_secret=\"\"\n",
    "username=\"midasIIITD\"\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def user_tweets(api,user):\n",
    "    all_tweets = api.user_timeline(screen_name=user, count=1000, tweet_mode=\"extended\")\n",
    "    return all_tweets\n",
    "tweets=user_tweets(api,username)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though I passed 1000 as number of tweets parameter, it returns only 200 tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweepy.models.Status"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type((tweets[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is of type Status, we will need to change it to a suitable format, for our requirement json or jsonlines\n",
    "We have a _json field in this status file, which refers to the json response sent by twitter. We will extract and store that.\n",
    "Hence we will get a list of dictionaries. That will be written to files of jsonl format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_jsons=[]\n",
    "for tweet in tweets:\n",
    "        tweet_jsons.append(tweet._json)\n",
    "\n",
    "with jsonlines.open('tweets.jsonl', mode='w') as writer:\n",
    "    writer.write(tweet_jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tweets[0]._json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the first talk of writing to json file is completed. We'll read from the json file now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_jsons=[]\n",
    "with jsonlines.open('tweets.jsonl') as reader:\n",
    "    for main_list in reader:\n",
    "        tweet_jsons = main_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created_at\n",
      "id\n",
      "id_str\n",
      "full_text\n",
      "truncated\n",
      "display_text_range\n",
      "entities\n",
      "source\n",
      "in_reply_to_status_id\n",
      "in_reply_to_status_id_str\n",
      "in_reply_to_user_id\n",
      "in_reply_to_user_id_str\n",
      "in_reply_to_screen_name\n",
      "user\n",
      "geo\n",
      "coordinates\n",
      "place\n",
      "contributors\n",
      "is_quote_status\n",
      "retweet_count\n",
      "favorite_count\n",
      "favorited\n",
      "retweeted\n",
      "lang\n"
     ]
    }
   ],
   "source": [
    "for key in tweet_jsons[0]:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have multiple keys available in the json. However, we need to extract only a few out of them now.\n",
    "Those include\n",
    "\n",
    "full_text=The text of the tweet\n",
    "\n",
    "created_at= Date and time of the tweet\n",
    "\n",
    "favourite_count= The number of likes\n",
    "\n",
    "retweet_count= The number of retweets\n",
    "\n",
    "For images it is a bit more complicated than others. First, we need to go into 'entities'. Then, we need to check for 'media', which may or may not be present. In objects in media, if the type attribute is 'photo', then there is an image. In case of multiple images, multiple objects with type 'photo' will be present.\n",
    "\n",
    "There are two cases:\n",
    "1) The tweet is a tweet by the user\n",
    "2) The tweet is a retweet\n",
    "In case the tweet is a retweet, we need to get all the text,image, likes,retweet data from the original field, which can be done by utilising ['retweeted_status'] key. The text data might be truncated if we dont utilise retweeted_status attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(tweet):\n",
    "    info_dict={} #this dictionary will be returned\n",
    "    if 'retweeted_status' in tweet.keys():\n",
    "        info_dict['text'] = tweet['retweeted_status']['full_text']\n",
    "        info_dict['date-time']=tweet['created_at'] \n",
    "        info_dict['likes']=tweet['retweeted_status']['favorite_count']\n",
    "        info_dict['retweets']=tweet['retweeted_status']['retweet_count']\n",
    "        #now about the image task!\n",
    "        if 'media' in tweet['retweeted_status']['entities'].keys():\n",
    "            num = 0\n",
    "            for media_objects in tweet['retweeted_status']['entities']['media']:\n",
    "                if media_objects['type'] == 'photo':\n",
    "                    num+=1\n",
    "            if (num>0):\n",
    "                info_dict['images']= str(num)\n",
    "            else:\n",
    "                info_dict['images']=  \"None\"\n",
    "        else:\n",
    "            info_dict['images']=  \"None\"\n",
    "        return info_dict\n",
    "    else:\n",
    "        info_dict['text'] = tweet['full_text']\n",
    "        info_dict['date-time']=tweet['created_at'] \n",
    "        info_dict['likes']=tweet['favorite_count']\n",
    "        info_dict['retweets']=tweet['retweet_count']\n",
    "        if 'media' in tweet['entities'].keys():\n",
    "            num = 0\n",
    "            for media_objects in tweet['entities']['media']:\n",
    "                if media_objects['type'] == 'photo':\n",
    "                    num+=1\n",
    "            if (num>0):\n",
    "                info_dict['images']= str(num)\n",
    "            else:\n",
    "                info_dict['images']=  \"None\"\n",
    "        else:\n",
    "            info_dict['images']=  \"None\"\n",
    "        return info_dict\n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_info=[]\n",
    "for tweet in tweet_jsons:\n",
    "    info_dict=extract_info(tweet)\n",
    "    list_of_info.append([info_dict['text'],info_dict['date-time'],info_dict['likes'], info_dict['retweets'],info_dict['images']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet's text</th>\n",
       "      <th>Date-Time</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We have emailed the task details to all candidates who have applied to @midasIIITD internship through IIITD portal. Kindly check your spam folder if you have not received the email. We will evaluate all solutions received until April 10 midnight and announce results by April 14.</td>\n",
       "      <td>Fri Apr 05 16:08:37 +0000 2019</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our NAACL paper on polarization in language on Twitter surrounding mass shootings is up on arXiv! https://t.co/g7wiegXxDg\\nThis is the first lead-author paper from Dora Demszky; she put a huge amount of work into it and I think it turned out extremely well.</td>\n",
       "      <td>Fri Apr 05 04:05:11 +0000 2019</td>\n",
       "      <td>46</td>\n",
       "      <td>15</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Effective Transfer Learning For NLP https://t.co/Z1m0AzlfVv https://t.co/ccX4Uhxjn8</td>\n",
       "      <td>Fri Apr 05 04:04:43 +0000 2019</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What’s new in @Stanford CS224N Natural Language Processing with Deep Learning for 2019? Question answering—1D CNNs—subword models—contextual word representations—transformers—generation—bias. YT playlist https://t.co/gFwwXJqYuQ – CS224N online hub https://t.co/HTnMzCAjS3 #NLProc https://t.co/rZKQvfUhiF</td>\n",
       "      <td>Wed Apr 03 18:31:53 +0000 2019</td>\n",
       "      <td>221</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today we're releasing a large-scale extendable dataset of mathematical questions, for training (and evaluating the abilities of) neural models that can reason algebraically. \\n\\nPaper: https://t.co/D8g477gcQ4\\nCode and data: https://t.co/QvR2WkK7j2 https://t.co/EWqNqaOUd5</td>\n",
       "      <td>Wed Apr 03 17:04:32 +0000 2019</td>\n",
       "      <td>2335</td>\n",
       "      <td>841</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                      Tweet's text  \\\n",
       "0  We have emailed the task details to all candidates who have applied to @midasIIITD internship through IIITD portal. Kindly check your spam folder if you have not received the email. We will evaluate all solutions received until April 10 midnight and announce results by April 14.                           \n",
       "1  Our NAACL paper on polarization in language on Twitter surrounding mass shootings is up on arXiv! https://t.co/g7wiegXxDg\\nThis is the first lead-author paper from Dora Demszky; she put a huge amount of work into it and I think it turned out extremely well.                                                 \n",
       "2  Effective Transfer Learning For NLP https://t.co/Z1m0AzlfVv https://t.co/ccX4Uhxjn8                                                                                                                                                                                                                               \n",
       "3  What’s new in @Stanford CS224N Natural Language Processing with Deep Learning for 2019? Question answering—1D CNNs—subword models—contextual word representations—transformers—generation—bias. YT playlist https://t.co/gFwwXJqYuQ – CS224N online hub https://t.co/HTnMzCAjS3 #NLProc https://t.co/rZKQvfUhiF   \n",
       "4  Today we're releasing a large-scale extendable dataset of mathematical questions, for training (and evaluating the abilities of) neural models that can reason algebraically. \\n\\nPaper: https://t.co/D8g477gcQ4\\nCode and data: https://t.co/QvR2WkK7j2 https://t.co/EWqNqaOUd5                                  \n",
       "\n",
       "                        Date-Time  Likes  Retweets Images  \n",
       "0  Fri Apr 05 16:08:37 +0000 2019  6      1         None   \n",
       "1  Fri Apr 05 04:05:11 +0000 2019  46     15        None   \n",
       "2  Fri Apr 05 04:04:43 +0000 2019  19     10        1      \n",
       "3  Wed Apr 03 18:31:53 +0000 2019  221    55        1      \n",
       "4  Wed Apr 03 17:04:32 +0000 2019  2335   841       1      "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list_of_info)\n",
    "df.columns = [\"Tweet's text\", \"Date-Time\", \"Likes\", \"Retweets\",\"Images\"]\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
