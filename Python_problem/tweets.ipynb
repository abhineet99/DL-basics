{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For importing dependencies. Tweepy is a python library which makes using Twitter API an easier task. jsonlines and json are the formats that we are going to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import jsonlines\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard twitter api protocol. Please update the following cells with your own keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key=\"\"\n",
    "consumer_secret=\"\"\n",
    "access_token=\"\"\n",
    "access_secret=\"\"\n",
    "\n",
    "\n",
    "\n",
    "username=\"midasIIITD\"\n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to fetch tweets through API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def user_tweets(api,user):\n",
    "    all_tweets = api.user_timeline(screen_name=user, count=1000, tweet_mode=\"extended\")\n",
    "    return all_tweets\n",
    "tweets=user_tweets(api,username)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though I passed 1000 as number of tweets parameter, it returns only 200 tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweepy.models.Status"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type((tweets[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is of type Status, we will need to change it to a suitable format, for our requirement json or jsonlines\n",
    "We have a _json field in this status file, which refers to the json response sent by twitter. We will extract and store that.\n",
    "Hence we will get a list of dictionaries. That will be written to files of jsonl format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_jsons=[]\n",
    "for tweet in tweets:\n",
    "        tweet_jsons.append(tweet._json)\n",
    "\n",
    "with jsonlines.open('tweets.jsonl', mode='w') as writer:\n",
    "    writer.write(tweet_jsons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the first talk of writing to json file is completed. We'll read from the json file now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_jsons=[]\n",
    "with jsonlines.open('tweets.jsonl') as reader:\n",
    "    for main_list in reader:\n",
    "        tweet_jsons = main_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created_at\n",
      "id\n",
      "id_str\n",
      "full_text\n",
      "truncated\n",
      "display_text_range\n",
      "entities\n",
      "source\n",
      "in_reply_to_status_id\n",
      "in_reply_to_status_id_str\n",
      "in_reply_to_user_id\n",
      "in_reply_to_user_id_str\n",
      "in_reply_to_screen_name\n",
      "user\n",
      "geo\n",
      "coordinates\n",
      "place\n",
      "contributors\n",
      "is_quote_status\n",
      "retweet_count\n",
      "favorite_count\n",
      "favorited\n",
      "retweeted\n",
      "lang\n"
     ]
    }
   ],
   "source": [
    "for key in tweet_jsons[0]:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have multiple keys available in the json. However, we need to extract only a few out of them now.\n",
    "Those include\n",
    "\n",
    "full_text=The text of the tweet\n",
    "\n",
    "created_at= Date and time of the tweet\n",
    "\n",
    "favourite_count= The number of likes\n",
    "\n",
    "retweet_count= The number of retweets\n",
    "\n",
    "For images it is a bit more complicated than others. First, we need to go into 'entities'. Then, we need to check for 'media', which may or may not be present. In objects in media, if the type attribute is 'photo', then there is an image. In case of multiple images, multiple objects with type 'photo' will be present.\n",
    "\n",
    "There are two cases:\n",
    "\n",
    "1) The tweet is a tweet by the user\n",
    "\n",
    "2) The tweet is a retweet\n",
    "In case the tweet is a retweet, we need to get all the text,image, likes,retweet data from the original field, which can be done by utilising ['retweeted_status'] key. The text data might be truncated if we dont utilise retweeted_status attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(tweet):\n",
    "    info_dict={} #this dictionary will be returned\n",
    "    if 'retweeted_status' in tweet.keys():  # the case when tweet is a retweet\n",
    "        full_text=tweet['retweeted_status']['full_text'].split('\\n')\n",
    "        info_dict['text'] = ' '.join(full_text)\n",
    "        info_dict['date-time']=tweet['created_at'] \n",
    "        info_dict['likes']=tweet['retweeted_status']['favorite_count']\n",
    "        info_dict['retweets']=tweet['retweeted_status']['retweet_count']\n",
    "        #now about the image task!\n",
    "        if 'media' in tweet['retweeted_status']['entities'].keys():\n",
    "            num = 0\n",
    "            for media_objects in tweet['retweeted_status']['entities']['media']:\n",
    "                if media_objects['type'] == 'photo':\n",
    "                    num+=1\n",
    "            if (num>0):\n",
    "                info_dict['images']= str(num)\n",
    "            else:\n",
    "                info_dict['images']=  \"None\"\n",
    "        else:\n",
    "            info_dict['images']=  \"None\"\n",
    "        return info_dict\n",
    "    else: # if the tweet is original tweet\n",
    "        full_text=tweet['full_text'].split('\\n')\n",
    "        info_dict['text'] = ' '.join(full_text)\n",
    "        info_dict['date-time']=tweet['created_at'] \n",
    "        info_dict['likes']=tweet['favorite_count']\n",
    "        info_dict['retweets']=tweet['retweet_count']\n",
    "        if 'media' in tweet['entities'].keys():\n",
    "            num = 0\n",
    "            for media_objects in tweet['entities']['media']:\n",
    "                if media_objects['type'] == 'photo':\n",
    "                    num+=1\n",
    "            if (num>0):\n",
    "                info_dict['images']= str(num)\n",
    "            else:\n",
    "                info_dict['images']=  \"None\"\n",
    "        else:\n",
    "            info_dict['images']=  \"None\"\n",
    "        return info_dict\n",
    "        \n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "making a list of all required attributes, so that pandas dataframe can easily be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_info=[]\n",
    "for tweet in tweet_jsons:\n",
    "    info_dict=extract_info(tweet)\n",
    "    list_of_info.append([info_dict['text'],info_dict['date-time'],info_dict['likes'], info_dict['retweets'],info_dict['images']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet's text</th>\n",
       "      <th>Date-Time</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We have emailed the task details to all candidates who have applied to @midasIIITD internship through IIITD portal. Kindly check your spam folder if you have not received the email. We will evaluate all solutions received until April 10 midnight and announce results by April 14.</td>\n",
       "      <td>Fri Apr 05 16:08:37 +0000 2019</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our NAACL paper on polarization in language on Twitter surrounding mass shootings is up on arXiv! https://t.co/g7wiegXxDg This is the first lead-author paper from Dora Demszky; she put a huge amount of work into it and I think it turned out extremely well.</td>\n",
       "      <td>Fri Apr 05 04:05:11 +0000 2019</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Effective Transfer Learning For NLP https://t.co/Z1m0AzlfVv https://t.co/ccX4Uhxjn8</td>\n",
       "      <td>Fri Apr 05 04:04:43 +0000 2019</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What’s new in @Stanford CS224N Natural Language Processing with Deep Learning for 2019? Question answering—1D CNNs—subword models—contextual word representations—transformers—generation—bias. YT playlist https://t.co/gFwwXJqYuQ – CS224N online hub https://t.co/HTnMzCAjS3 #NLProc https://t.co/rZKQvfUhiF</td>\n",
       "      <td>Wed Apr 03 18:31:53 +0000 2019</td>\n",
       "      <td>222</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Today we're releasing a large-scale extendable dataset of mathematical questions, for training (and evaluating the abilities of) neural models that can reason algebraically.   Paper: https://t.co/D8g477gcQ4 Code and data: https://t.co/QvR2WkK7j2 https://t.co/EWqNqaOUd5</td>\n",
       "      <td>Wed Apr 03 17:04:32 +0000 2019</td>\n",
       "      <td>2338</td>\n",
       "      <td>841</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Congratulations Jitendra Malik !  Awards are raining on FAIRies these days... https://t.co/1WNcSeQLZe</td>\n",
       "      <td>Wed Apr 03 09:03:40 +0000 2019</td>\n",
       "      <td>150</td>\n",
       "      <td>16</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Another chance to take admission in the Ph.D. program in IIIT Delhi.  Admissions open for Ph.D. program mathematics   Log on to know more and apply: https://t.co/KgrmqscaIm  #Admissions</td>\n",
       "      <td>Wed Apr 03 07:46:02 +0000 2019</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dear @midasIIITD internship candidates who have submitted their solutions to the task, we have sent you an email regarding your results.   Students who have applied through @IIITDelhi, you will soon be contacted on the internship task.   #MIDAS #Summer #Research #Internship</td>\n",
       "      <td>Tue Apr 02 04:20:13 +0000 2019</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Looking forward to your paper submission to @IEEEBigMM19.   Important Dates: Regular Paper: 11:59pm PST, May 10, 2019      Short Paper: 11:59pm PST, May 10, 2019    Industry Paper: 11:59pm PST, May 10, 2019   Demonstration Paper: 11:59pm PST, May 10, 2019  Contact TPC @RatnRajiv</td>\n",
       "      <td>Tue Apr 02 02:44:54 +0000 2019</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Reproducibility in multimedia research in @sigmm records https://t.co/hOyMxtmy7A Plus reminder to past-year authors: Today 1 April AOE is the day to submit your repro abstract for @ACMMM19</td>\n",
       "      <td>Tue Apr 02 02:35:44 +0000 2019</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Online application for https://t.co/DJFDrQsHZP. Admission 2019 at @IIITDelhi has been open  Log on to know more and apply: https://t.co/w7d2UMTVh7  Last Date: 18th April 2019  #MTech #IIITD #Admission</td>\n",
       "      <td>Mon Apr 01 06:53:08 +0000 2019</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A final reminder of the Reproducibility Track: Authors of 2017 and 2018 papers are invited to submit a short reproducibility paper: ACM MM 2019 will feature a reproducibility poster session https://t.co/q2IFt9lTac https://t.co/zUJEmH6HAd</td>\n",
       "      <td>Sun Mar 31 10:21:24 +0000 2019</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Thanks for the support and help @debanjanbhucs @RatnRajiv and @midasIIITD. It was a great learning experience! Glad to be part of the team. https://t.co/g45tIJQ18s</td>\n",
       "      <td>Fri Mar 29 19:43:24 +0000 2019</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Since SemEval-2019 will be held June 6-7, 2019 in Minneapolis, USA, collocated with NAACL-HLT 2019, it will great students for @midasIIITD students to attend the conference and learn from worldclass researchers. +@aggarwal_kartik</td>\n",
       "      <td>Fri Mar 29 17:16:40 +0000 2019</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>+@aggarwal_kartik. Congrats! Wish you many more success.</td>\n",
       "      <td>Fri Mar 29 17:04:30 +0000 2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Our work (@midasIIITD ) accepted at SemEval 2019 at @NAACLHLT : \"MIDAS at SemEval-2019 Task 9: Suggestion Mining from Online Reviews using ULMFiT\".  We ranked 10th on the leaderboard. Code available at: https://t.co/Yuqbc3WjnB</td>\n",
       "      <td>Fri Mar 29 17:03:29 +0000 2019</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Congratulations! @midasIIITD team, @isarth23 @LaibaMehnaz @Simcyy @debanjanbhucs @RatnRajiv @the_dhumketu for getting two papers accepted at SemEval 2019.  Many thanks to our collaborators Haimin and Karan for their help.  #NLP #Research #SocialMedia #Analytics #DeepLearning</td>\n",
       "      <td>Fri Mar 29 17:02:24 +0000 2019</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>@EEMLcommunity @radamihalcea too many deadlines coming, @ACMMM19 @IEEEBigMM19 @EEMLcommunity</td>\n",
       "      <td>Fri Mar 29 05:35:22 +0000 2019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CS224N Natural Language Processing with Deep Learning 2019 @Stanford course videos by @chrmanning, @abigail_e_see &amp;amp; guests are now mostly available (16 of 20). Big update from 2017. YouTube playlist: https://t.co/gFwwXJqYuQ – new CS224N online hub: https://t.co/HTnMzCAjS3 #NLProc https://t.co/3S9iDX2e2o</td>\n",
       "      <td>Thu Mar 28 16:55:01 +0000 2019</td>\n",
       "      <td>1955</td>\n",
       "      <td>710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Learn PyTorch by running on Google GPUs for free. https://t.co/pt038TMnWR</td>\n",
       "      <td>Thu Mar 28 16:54:37 +0000 2019</td>\n",
       "      <td>644</td>\n",
       "      <td>157</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                            Tweet's text  \\\n",
       "0   We have emailed the task details to all candidates who have applied to @midasIIITD internship through IIITD portal. Kindly check your spam folder if you have not received the email. We will evaluate all solutions received until April 10 midnight and announce results by April 14.                                \n",
       "1   Our NAACL paper on polarization in language on Twitter surrounding mass shootings is up on arXiv! https://t.co/g7wiegXxDg This is the first lead-author paper from Dora Demszky; she put a huge amount of work into it and I think it turned out extremely well.                                                       \n",
       "2   Effective Transfer Learning For NLP https://t.co/Z1m0AzlfVv https://t.co/ccX4Uhxjn8                                                                                                                                                                                                                                    \n",
       "3   What’s new in @Stanford CS224N Natural Language Processing with Deep Learning for 2019? Question answering—1D CNNs—subword models—contextual word representations—transformers—generation—bias. YT playlist https://t.co/gFwwXJqYuQ – CS224N online hub https://t.co/HTnMzCAjS3 #NLProc https://t.co/rZKQvfUhiF        \n",
       "4   Today we're releasing a large-scale extendable dataset of mathematical questions, for training (and evaluating the abilities of) neural models that can reason algebraically.   Paper: https://t.co/D8g477gcQ4 Code and data: https://t.co/QvR2WkK7j2 https://t.co/EWqNqaOUd5                                          \n",
       "5   Congratulations Jitendra Malik !  Awards are raining on FAIRies these days... https://t.co/1WNcSeQLZe                                                                                                                                                                                                                  \n",
       "6   Another chance to take admission in the Ph.D. program in IIIT Delhi.  Admissions open for Ph.D. program mathematics   Log on to know more and apply: https://t.co/KgrmqscaIm  #Admissions                                                                                                                              \n",
       "7   Dear @midasIIITD internship candidates who have submitted their solutions to the task, we have sent you an email regarding your results.   Students who have applied through @IIITDelhi, you will soon be contacted on the internship task.   #MIDAS #Summer #Research #Internship                                     \n",
       "8   Looking forward to your paper submission to @IEEEBigMM19.   Important Dates: Regular Paper: 11:59pm PST, May 10, 2019      Short Paper: 11:59pm PST, May 10, 2019    Industry Paper: 11:59pm PST, May 10, 2019   Demonstration Paper: 11:59pm PST, May 10, 2019  Contact TPC @RatnRajiv                                \n",
       "9   Reproducibility in multimedia research in @sigmm records https://t.co/hOyMxtmy7A Plus reminder to past-year authors: Today 1 April AOE is the day to submit your repro abstract for @ACMMM19                                                                                                                           \n",
       "10  Online application for https://t.co/DJFDrQsHZP. Admission 2019 at @IIITDelhi has been open  Log on to know more and apply: https://t.co/w7d2UMTVh7  Last Date: 18th April 2019  #MTech #IIITD #Admission                                                                                                               \n",
       "11  A final reminder of the Reproducibility Track: Authors of 2017 and 2018 papers are invited to submit a short reproducibility paper: ACM MM 2019 will feature a reproducibility poster session https://t.co/q2IFt9lTac https://t.co/zUJEmH6HAd                                                                          \n",
       "12  Thanks for the support and help @debanjanbhucs @RatnRajiv and @midasIIITD. It was a great learning experience! Glad to be part of the team. https://t.co/g45tIJQ18s                                                                                                                                                    \n",
       "13  Since SemEval-2019 will be held June 6-7, 2019 in Minneapolis, USA, collocated with NAACL-HLT 2019, it will great students for @midasIIITD students to attend the conference and learn from worldclass researchers. +@aggarwal_kartik                                                                                  \n",
       "14  +@aggarwal_kartik. Congrats! Wish you many more success.                                                                                                                                                                                                                                                               \n",
       "15  Our work (@midasIIITD ) accepted at SemEval 2019 at @NAACLHLT : \"MIDAS at SemEval-2019 Task 9: Suggestion Mining from Online Reviews using ULMFiT\".  We ranked 10th on the leaderboard. Code available at: https://t.co/Yuqbc3WjnB                                                                                     \n",
       "16  Congratulations! @midasIIITD team, @isarth23 @LaibaMehnaz @Simcyy @debanjanbhucs @RatnRajiv @the_dhumketu for getting two papers accepted at SemEval 2019.  Many thanks to our collaborators Haimin and Karan for their help.  #NLP #Research #SocialMedia #Analytics #DeepLearning                                    \n",
       "17  @EEMLcommunity @radamihalcea too many deadlines coming, @ACMMM19 @IEEEBigMM19 @EEMLcommunity                                                                                                                                                                                                                           \n",
       "18  CS224N Natural Language Processing with Deep Learning 2019 @Stanford course videos by @chrmanning, @abigail_e_see &amp; guests are now mostly available (16 of 20). Big update from 2017. YouTube playlist: https://t.co/gFwwXJqYuQ – new CS224N online hub: https://t.co/HTnMzCAjS3 #NLProc https://t.co/3S9iDX2e2o   \n",
       "19  Learn PyTorch by running on Google GPUs for free. https://t.co/pt038TMnWR                                                                                                                                                                                                                                              \n",
       "\n",
       "                         Date-Time  Likes  Retweets Images  \n",
       "0   Fri Apr 05 16:08:37 +0000 2019  7      1         None   \n",
       "1   Fri Apr 05 04:05:11 +0000 2019  48     16        None   \n",
       "2   Fri Apr 05 04:04:43 +0000 2019  19     10        1      \n",
       "3   Wed Apr 03 18:31:53 +0000 2019  222    55        1      \n",
       "4   Wed Apr 03 17:04:32 +0000 2019  2338   841       1      \n",
       "5   Wed Apr 03 09:03:40 +0000 2019  150    16        None   \n",
       "6   Wed Apr 03 07:46:02 +0000 2019  4      4         None   \n",
       "7   Tue Apr 02 04:20:13 +0000 2019  8      1         None   \n",
       "8   Tue Apr 02 02:44:54 +0000 2019  5      1         None   \n",
       "9   Tue Apr 02 02:35:44 +0000 2019  9      7         None   \n",
       "10  Mon Apr 01 06:53:08 +0000 2019  6      1         None   \n",
       "11  Sun Mar 31 10:21:24 +0000 2019  12     10        1      \n",
       "12  Fri Mar 29 19:43:24 +0000 2019  7      2         None   \n",
       "13  Fri Mar 29 17:16:40 +0000 2019  9      1         None   \n",
       "14  Fri Mar 29 17:04:30 +0000 2019  2      0         None   \n",
       "15  Fri Mar 29 17:03:29 +0000 2019  6      1         None   \n",
       "16  Fri Mar 29 17:02:24 +0000 2019  9      1         None   \n",
       "17  Fri Mar 29 05:35:22 +0000 2019  0      0         None   \n",
       "18  Thu Mar 28 16:55:01 +0000 2019  1955   710       1      \n",
       "19  Thu Mar 28 16:54:37 +0000 2019  644    157       None   "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list_of_info)\n",
    "df.columns = [\"Tweet's text\", \"Date-Time\", \"Likes\", \"Retweets\",\"Images\"]\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "df.head(20) # diplaying for 20 tweets, if all required, print(df) can be used\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
