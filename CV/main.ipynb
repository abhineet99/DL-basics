{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns #helps in visualising data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels=\"dataset/train_label.pkl\"\n",
    "train_images=\"dataset/train_image.pkl\"\n",
    "test_images=\"dataset/test_image.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING AND VISUALISING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_objects=[]\n",
    "with (open(train_images,\"rb\")) as openfile: #from stackoverflow and pickle docs\n",
    "    while True:\n",
    "        try:\n",
    "            file_objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "8000\n",
      "<class 'list'>\n",
      "784\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(len(file_objects))\n",
    "print(len(file_objects[0]))\n",
    "print(type(file_objects[0][1]))\n",
    "print(len(file_objects[0][1]))\n",
    "print(type(file_objects[0][1][1]))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen, the data contains 8000 lists of 784 ints, that is 28*28, hence its a reasonable assumption that these are pixel values, however we will visualise to confirm the same. \n",
    "After checking the output of print (file_objects[0][1]), the values range from 0 to 255 hence the assumption is true.\n",
    "Now, we need to check if 8000 labels are present or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_label_objects=[]\n",
    "with (open(training_labels,\"rb\")) as openfile: #from stackoverflow and pickle docs\n",
    "    while True:\n",
    "        try:\n",
    "            file_label_objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_label_objects[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 8000 training labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_labels=file_label_objects[0]\n",
    "input_class_graph=sns.countplot(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so data is evenly distributed, and there are 4 classes, now i will visualise image , and we will do mapping of classes from 0,2,3,6 to 0,1,2,3. It will result in less size of one hot encoded vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=file_objects[0]\n",
    "for i in range(len(train_labels)):\n",
    "    if (train_labels[i] == 2):\n",
    "        train_labels[i]=1\n",
    "    elif (train_labels[i]  == 3):\n",
    "        train_labels[i]=2\n",
    "    elif (train_labels[i]  == 6):\n",
    "        train_labels[i]=3\n",
    "     \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[7000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a pandas dataframe, easier to handle stuff\n",
    "train_df=pd.DataFrame(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df.values.reshape(-1,28,28,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g=plt.imshow(train_df[7007][:,:,0])\n",
    "train_labels[7007]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# after various iterations, it appears as if these are different type of clothings, although i feel class 6 has some common attributes with other classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SO we have classes like tees, pullover, dresses, shirt. To me, it appears as if shirt class can be confused with others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to create a validation set, as the labels are in a sequential manner, the inbuilt function(keras) will not randomise and pick last few values, hence validation set wont be generalised, so I'll use sklearn for the same\n",
    "from sklearn.model_selection import train_test_split\n",
    "XTraining, XValidation, YTraining, YValidation = train_test_split(train_df,train_labels,stratify=train_labels,test_size=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#now the time to create model, I'll be using Keras to create a CNN\n",
    "#for one hot encodingx importing 'to categorical'\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler, ReduceLROnPlateau\n",
    "#one hot encoding\n",
    "YTraining = to_categorical(YTraining)\n",
    "YValidation = to_categorical(YValidation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a CNN architecture\n",
    "Regarding the layers:\n",
    "Conv2d: basically the learnable filters with 3*3 kernel size in this case\n",
    "MaxPool2D: acts as a downsampling filters, chooses max value among neighboring pixels, more global features can be learnt\n",
    "Dropout: for regularisation(to reduce overfitting)\n",
    "Relu, Softmax are used as activations\n",
    "BatchNormalisation for quicker training\n",
    "Flatten to make use of fully connected layer after convolutional layers. Dense layer is the classifier layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu',\n",
    "                 input_shape = (28, 28, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the essence of image category remains same even if images are altered in terms of shifting,zooming,tilting in this case, I will apply these standard data augmentation techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(zoom_range = 0.1,\n",
    "                            height_shift_range = 0.1,\n",
    "                            width_shift_range = 0.1,\n",
    "                            rotation_range = 10,horizontal_flip=True,vertical_flip=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer = Adam(lr=1e-3), metrics=[\"accuracy\"]) # adam as optimiser, crossentropy log loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning rate annealing, to slow down learning rate on plateau, so that the model can coverge to more precise point\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "600/600 [==============================] - 21s 35ms/step - loss: 0.9972 - acc: 0.5864 - val_loss: 0.6504 - val_acc: 0.7338\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 18s 29ms/step - loss: 0.7705 - acc: 0.6743 - val_loss: 0.5904 - val_acc: 0.7594\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 19s 32ms/step - loss: 0.7067 - acc: 0.7114 - val_loss: 0.5990 - val_acc: 0.7550\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 21s 34ms/step - loss: 0.6941 - acc: 0.7157 - val_loss: 0.5580 - val_acc: 0.7937\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 20s 34ms/step - loss: 0.6696 - acc: 0.7314 - val_loss: 0.7692 - val_acc: 0.7075\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 21s 35ms/step - loss: 0.6441 - acc: 0.7439 - val_loss: 0.4781 - val_acc: 0.8044\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 20s 33ms/step - loss: 0.6322 - acc: 0.7471 - val_loss: 0.4934 - val_acc: 0.7994\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 24s 39ms/step - loss: 0.6163 - acc: 0.7590 - val_loss: 0.5038 - val_acc: 0.8075\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.6018 - acc: 0.7690 - val_loss: 0.5324 - val_acc: 0.7994\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 19s 31ms/step - loss: 0.5782 - acc: 0.7743 - val_loss: 0.5185 - val_acc: 0.8169\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 20s 34ms/step - loss: 0.5883 - acc: 0.7714 - val_loss: 0.4620 - val_acc: 0.8156\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 21s 35ms/step - loss: 0.5733 - acc: 0.7806 - val_loss: 0.4420 - val_acc: 0.8331\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 23s 39ms/step - loss: 0.5614 - acc: 0.7785 - val_loss: 0.4311 - val_acc: 0.8325\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 21s 35ms/step - loss: 0.5558 - acc: 0.7818 - val_loss: 0.4431 - val_acc: 0.8394\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 21s 35ms/step - loss: 0.5405 - acc: 0.7893 - val_loss: 0.4368 - val_acc: 0.8369\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.5379 - acc: 0.7905 - val_loss: 0.4712 - val_acc: 0.8225\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 24s 41ms/step - loss: 0.5334 - acc: 0.7975 - val_loss: 0.4516 - val_acc: 0.8363\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.5131 - acc: 0.8008 - val_loss: 0.3806 - val_acc: 0.8575\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.4785 - acc: 0.8158 - val_loss: 0.4339 - val_acc: 0.8400\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 20s 33ms/step - loss: 0.4779 - acc: 0.8130 - val_loss: 0.3926 - val_acc: 0.8544\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(datagen.flow(XTraining, YTraining, batch_size=16),\n",
    "                            steps_per_epoch=600,\n",
    "                           epochs=20,\n",
    "                           verbose=1,\n",
    "                           validation_data=(XValidation, YValidation), \n",
    "                           callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "600/600 [==============================] - 19s 32ms/step - loss: 0.4740 - acc: 0.8154 - val_loss: 0.4088 - val_acc: 0.8500\n",
      "Epoch 2/40\n",
      "600/600 [==============================] - 14s 24ms/step - loss: 0.4765 - acc: 0.8213 - val_loss: 0.3992 - val_acc: 0.8525\n",
      "Epoch 3/40\n",
      "600/600 [==============================] - 15s 24ms/step - loss: 0.4685 - acc: 0.8198 - val_loss: 0.4085 - val_acc: 0.8456\n",
      "Epoch 4/40\n",
      "600/600 [==============================] - 19s 32ms/step - loss: 0.4661 - acc: 0.8175 - val_loss: 0.3860 - val_acc: 0.8588\n",
      "Epoch 5/40\n",
      "600/600 [==============================] - 14s 23ms/step - loss: 0.4567 - acc: 0.8235 - val_loss: 0.3872 - val_acc: 0.8588\n",
      "Epoch 6/40\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.4719 - acc: 0.8148 - val_loss: 0.3928 - val_acc: 0.8519\n",
      "Epoch 7/40\n",
      "600/600 [==============================] - 17s 29ms/step - loss: 0.4577 - acc: 0.8237 - val_loss: 0.3936 - val_acc: 0.8531\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 8/40\n",
      "600/600 [==============================] - 15s 26ms/step - loss: 0.4584 - acc: 0.8242 - val_loss: 0.3879 - val_acc: 0.8569\n",
      "Epoch 9/40\n",
      "600/600 [==============================] - 21s 35ms/step - loss: 0.4567 - acc: 0.8273 - val_loss: 0.3968 - val_acc: 0.8506\n",
      "Epoch 10/40\n",
      "600/600 [==============================] - 18s 31ms/step - loss: 0.4378 - acc: 0.8292 - val_loss: 0.3968 - val_acc: 0.8488\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 11/40\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.4663 - acc: 0.8244 - val_loss: 0.3886 - val_acc: 0.8538\n",
      "Epoch 12/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.4425 - acc: 0.8248 - val_loss: 0.3962 - val_acc: 0.8494\n",
      "Epoch 13/40\n",
      "600/600 [==============================] - 15s 24ms/step - loss: 0.4638 - acc: 0.8210 - val_loss: 0.3906 - val_acc: 0.8544\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 14/40\n",
      "600/600 [==============================] - 18s 31ms/step - loss: 0.4369 - acc: 0.8327 - val_loss: 0.3904 - val_acc: 0.8525\n",
      "Epoch 15/40\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.4593 - acc: 0.8219 - val_loss: 0.3938 - val_acc: 0.8506\n",
      "Epoch 16/40\n",
      "600/600 [==============================] - 15s 24ms/step - loss: 0.4488 - acc: 0.8281 - val_loss: 0.3917 - val_acc: 0.8525\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "Epoch 17/40\n",
      "600/600 [==============================] - 14s 24ms/step - loss: 0.4422 - acc: 0.8240 - val_loss: 0.3938 - val_acc: 0.8512\n",
      "Epoch 18/40\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.4460 - acc: 0.8192 - val_loss: 0.3952 - val_acc: 0.8519\n",
      "Epoch 19/40\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.4420 - acc: 0.8248 - val_loss: 0.3980 - val_acc: 0.8488\n",
      "Epoch 20/40\n",
      "600/600 [==============================] - 14s 23ms/step - loss: 0.4496 - acc: 0.8271 - val_loss: 0.3944 - val_acc: 0.8506\n",
      "Epoch 21/40\n",
      "600/600 [==============================] - 16s 27ms/step - loss: 0.4494 - acc: 0.8185 - val_loss: 0.3957 - val_acc: 0.8525\n",
      "Epoch 22/40\n",
      "600/600 [==============================] - 14s 23ms/step - loss: 0.4441 - acc: 0.8235 - val_loss: 0.3962 - val_acc: 0.8512\n",
      "Epoch 23/40\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.4472 - acc: 0.8283 - val_loss: 0.3902 - val_acc: 0.8519\n",
      "Epoch 24/40\n",
      "600/600 [==============================] - 17s 28ms/step - loss: 0.4483 - acc: 0.8263 - val_loss: 0.3979 - val_acc: 0.8475\n",
      "Epoch 25/40\n",
      "600/600 [==============================] - 13s 22ms/step - loss: 0.4504 - acc: 0.8283 - val_loss: 0.3957 - val_acc: 0.8494\n",
      "Epoch 26/40\n",
      "600/600 [==============================] - 15s 25ms/step - loss: 0.4622 - acc: 0.8188 - val_loss: 0.3939 - val_acc: 0.8512\n",
      "Epoch 27/40\n",
      "600/600 [==============================] - 14s 23ms/step - loss: 0.4360 - acc: 0.8290 - val_loss: 0.3986 - val_acc: 0.8488\n",
      "Epoch 28/40\n",
      "600/600 [==============================] - 14s 23ms/step - loss: 0.4347 - acc: 0.8325 - val_loss: 0.3946 - val_acc: 0.8500\n",
      "Epoch 29/40\n",
      "600/600 [==============================] - 18s 30ms/step - loss: 0.4433 - acc: 0.8335 - val_loss: 0.3935 - val_acc: 0.8494\n",
      "Epoch 30/40\n",
      "133/600 [=====>........................] - ETA: 11s - loss: 0.4193 - acc: 0.8449"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer = Adam(lr=1e-4), metrics=[\"accuracy\"]) # adam as optimiser, crossentropy log loss function\n",
    "\n",
    "hist = model.fit_generator(datagen.flow(XTraining, YTraining, batch_size=8),\n",
    "                            steps_per_epoch=600,\n",
    "                           epochs=40,\n",
    "                           verbose=1,\n",
    "                           validation_data=(XValidation, YValidation), \n",
    "                           callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
